{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84822ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"sms_spam.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba6a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc23aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Cleaning\n",
    "# 2. EDA\n",
    "# 3. Text Preprocessing\n",
    "# 4. Model Building\n",
    "# 5. Evolution\n",
    "# 6. Improvement\n",
    "# 7. website\n",
    "# 8. Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380e6ea",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6843802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5574 entries, 0 to 5573\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    5574 non-null   object\n",
      " 1   text    5574 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b52dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya even those cookies have jelly on them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>ham</td>\n",
       "      <td>Maybe you should find something else to do ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks for ve lovely wisheds. You rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol ... Oh no babe, I wont be sliding into you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>ham</td>\n",
       "      <td>You flippin your shit yet?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                               text\n",
       "724   ham           Ya even those cookies have jelly on them\n",
       "4851  ham  Maybe you should find something else to do ins...\n",
       "1433  ham             Thanks for ve lovely wisheds. You rock\n",
       "1959  ham  Lol ... Oh no babe, I wont be sliding into you...\n",
       "1182  ham                         You flippin your shit yet?"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5544847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset.rename(columns={\"actual_name\":\"new_name\"}, inplace=True)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if have to rename the columns\n",
    "# use\n",
    "\"\"\"\n",
    "dataset.rename(columns={\"actual_name\":\"new_name\"}, inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f33b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf4e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['type']=encoder.fit_transform(dataset['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc7a18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0     0  Go until jurong point, crazy.. Available only ...\n",
       "1     0                      Ok lar... Joking wif u oni...\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     0  U dun say so early hor... U c already then say...\n",
       "4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662f86f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type    0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768240c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate values\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7643a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98cf0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e20017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769d3b4",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aac452f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0     0  Go until jurong point, crazy.. Available only ...\n",
       "1     0                      Ok lar... Joking wif u oni...\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     0  U dun say so early hor... U c already then say...\n",
       "4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54067108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4518\n",
       "1     642\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3a04bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['type'].value_counts(),labels=['ham','spam'],autopct='%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41c5dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39f14d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d613abfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000178F7ED4910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/punkit/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000178F7ED4550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/punkit/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000178F7ED43A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/punkit/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000178F7ED4E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/punkit/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000178F7ED4D00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/punkit/\n",
      "ERROR: Could not find a version that satisfies the requirement punkit\n",
      "ERROR: No matching distribution found for punkit\n"
     ]
    }
   ],
   "source": [
    "!pip install punkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "758aa726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkit: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95b0630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "812742c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-daffd193ee4f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['num_char']=df['text'].apply(len) # no. of char in every message\n"
     ]
    }
   ],
   "source": [
    "df['num_char']=df['text'].apply(len) # no. of char in every message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5898a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>0</td>\n",
       "      <td>Love it! The girls at the office may wonder wh...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               text  num_char\n",
       "3771     0  Love it! The girls at the office may wonder wh...        75"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0007a28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\anxua/nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4440a86caa4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# num of words  .... need to download nltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-4440a86caa4d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# num of words  .... need to download nltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [\n\u001b[0;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\anxua/nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# num of words  .... need to download nltk\n",
    "df['num_words']=df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22e7ffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>0</td>\n",
       "      <td>Dai i downloaded but there is only exe file wh...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               text  num_char\n",
       "5212     0  Dai i downloaded but there is only exe file wh...        91"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f52a6906",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\anxua/nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-9fc61639fbfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# num of sentences  .... need to download nltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_sent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-9fc61639fbfa>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# num of sentences  .... need to download nltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_sent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\anxua/nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\anxua\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# num of sentences  .... need to download nltk\n",
    "df['num_sent']=df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a5b7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\anxua\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\anxua\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\anxua\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\anxua\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anxua\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64cc32bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
